\chapter{Общие вопросы}

В этой главе приводятся основные понятия ML и DS. 


\section{Машинное обучение}

Машинное обучение (ML) - область искусственного интеллекта, изучающая самообучающиеся модели, то есть решаюшие поставленную задачу не по заранее запрограммированному алгоритму, а предварительно настраивая свое поведение согласно имеющимся данным. 

Обычно методы ML содержат свободные параметры, подбор которых наилучшим (в смысле имеющихся данных) образом и составляет процесс обучения алгоритма.


\section{Основные классы задач}


\section{Обнаружение аномалий}


\section{Контроль качества}

...оценка обобщающей способности...


\section{Недообучение}


\section{Переобучение}


\section{Регуляризация}


\section{Отбор признаков}


\section{Параметры алгоритма}


\section{Подбора метапараметров}


\section{Основные типы алгоритмов}


\section{Многоклассовая классификация}


\section{Дисбаланс классов}

...чем плохо... как бороться (over/undersampling/SMOTE)...
$http://www.machinelearning.ru/wiki/images/1/1c/Sem06_metrics.pdf$

\section{Ансамбли алгоритмов}


\section{Метрики классификации}

Пусть некоторый алгоритм $a$ решает задачу бинарной классификации с классами $0$ (негативный) и $1$ (позитивный).
Тестирование алгоритма $a$ проводится на $n$ объектах, ответы $y$ на которых известны. Пусть $TP$ и $TN$ - числа правильно классифицированных позитивных и негативных объектов соответственно. Аналогично, $FP$ и $FN$ - числа неправильно классифицированных позитивных и негативных объектов соответственно.

О качестве алгоритма $a$ можно судить по матрице ошибок:
\begin{center}
\begin{tabular}{ c c c }
     & y=1 & y=0 \\ 
 a=1 & TP  & FP \\  
 a=0 & FN  & TN    
\end{tabular}
\end{center}

Для оценки качества работы алгоритмов бинарной классификации обычно используются следующие основные метрики:

\begin{enumerate}
  \item Доля правильных ответов (accuracy): отношение числа правильных ответов к общему количеству. Проста в использовании, но плоха для несбалансированных выборок.
  \item Точность (precision): $TP/(TP + FP)$ - чем ближе значение к 1, тем меньше ложных срабатываний
  \item Полнота (recall): $TP/(TP + FN)$ - чем ближе значение к 1, тем меньше ложных пропусков
  \item F1-мера: $F = 2*P*R/(P + R)$ - усредняет, ловит и точность, и полноту
  \item F-мера: $F = (1+\beta^2)*P*R/(\beta^2P + R)$ - усредняет, ловит и точность, и полноту
  \item ROC AUC: площать под ROC кривой. Одна из наиболее популярных метрик в силу своей устойчивости к выбросам.
  \item PR AUC: площать под ROC кривой. Хороша, когда негативных объектов гораздо больше, чем позитивных.
\end{enumerate}

\section{Метрики многоклассовой классификации}


\section{ROC-AUC метрика}


\section{Индекс Джини}


\section{Метрики регрессии}


\section{Метрики кластеризации}


\section{Разложение ошибки алгоритма}


\section{Кривые валидации}


\section{Кривые обучения}


\section{Метрические методы}


\section{Метод ближайших соседей}


\section{Линейные методы}


\section{Линейная регрессия}


\section{Логистическая регрессия}

...отличие от линейной...


\section{SVM}


\section{Ядра и спрямляющие пространства}


\section{Решаюшие деревья}


\section{Случайный лес}

...отличие от беггинга над решающими деревьями...


\section{Градиентный бустинг}


\section{Байесовские методы}



