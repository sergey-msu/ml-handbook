\chapter{Математика}

В этой главе описаны основные математические понятия, необходимые для правильного понимания как основных, так и продвинутых методов ML. Охвачены: теория вероятностей, классическая и байесовская статистика, некоторые вопросы мат. анализа.


\section{Случайная величина}

Случайной величиной (RV) называется числовая функция $X$, определенная на некотором множестве элементарных исходов $\Omega$ (обычно подмножество $\mathbb{R}$ или $\mathbb{R}^n$), 

$$
X: \Omega\rightarrow\mathbb{R}.
$$

С прикладной точки зрения на RV часто смотрят как на генераторы случайных чисел с заданным распределением.

\textbf{Примеры:}
\begin{itemize}
    \item Рост людей, взятых из некоторой группы.
    \item Цвет фиксированного пикселя изображения, взятого из некоторого множества изображений.
    \item Некоторый признак из датасета ML задачи.
\end{itemize}


\section{Распределение случайной величины}

Если RV принимает дискретное множество значений $x_1,x_2,...$, то она полностью определяется значениями их вероятностей: $p_k=\mathbb{P}(X=x_k)$.

Если множество значений RV не дискретно, то RV может быть описана своей функцией распределения (CDF, Cumulative distribution function): $F(x)=\mathbb{P}(X<x)$.

В большинстве прикладных случаев CDF оказывается дифференцируемой функцией. Производная от CDF называется плотностью распределения случайной величины (PDF, Probability density function): $f(x)=F'(x)$. Таким образом, по определению 

$$
\mathbb{P}(a<X<b)=\int_{a}^{b}f(x)dx.
$$


\section{Выборка}

Выборкой объема $n$ из генеральной совокупности $X$ называется последовательность независимых и распределенных как $X$ случайных величин: 

$$
X_1, X_2, ..., X_n, \quad X_k \sim X
$$

На практике под выборкой понимают конкретные реализации величин $X_k$, то есть последовательность чисел $x_1, x_2, ..., x_n$.


\section{Закон больших чисел}

Закон больших чисел утверждает, что если $X_1, X_2, ..., X_n$ - выборка объема $n$ из генеральной совокупности $X$, то ее среднее с ростом $n$ становится все менее случайно и в конечном итоге стабилизируется к постоянной величине - среднему значению $X$:

$$
\frac{X_1+X_2+...+X_n}{n} \approx \mathbb{E}X, \quad n\rightarrow\infty.
$$ 


\section{Центральная предельная теорема}

Центральная предельная теорема (CLT) является в некотором смысле уточнением закона больших чисел.
В упрощенном варианте она утверждает, что если $X_1, X_2, ..., X_n$ - выборка объема $n$ из генеральной совокупности $X$, то ее распределение ее среднего при больших $n$ очень близко к нормальному,  

$$
\frac{X_1+X_2+...+X_n}{n} \approx N(\mu, \sigma^2/n), \quad \mu=EX, \sigma^2=DX, \quad n\rightarrow\infty.
$$

Заметим, что если совокупность распределена нормально, $X \sim N(\mu, \sigma^2)$, то предыдущая формула обращается в 
точное равенство при любых $n$.


\section{Приближенное вычисление интегралов}

Пусть $x_1, x_2, ..., x_n$ - реализация некоторой выборки из генеральной совокупности $X$, распределенной с некоторой плотностью $f(x)$. Если $Y = g(X)$ - случайная величина, являющаяся функцией $X$, то ее среднее есть по определению
$$
\mathbb{E}Y = \int g(x)f(x)dx.
$$
при неизвестной плоности этот интеграл может быть приблизительно вычислен как
$$
\mathbb{E}Y \approx \frac{1}{n}\sum_{i=1}^ng(x_i).
$$
В частности,
$$
\mathbb{E}X \approx \frac{1}{n}\sum_{i=1}^nx_i.
$$

\section{Статистики}

Пусть $X_1, X_2, ..., X_n$ - выборка объема $n$. Статистикой называется произвольная RV, являющаяся функцией выборки:

$$
T = T(X_1, X_2, ..., X_n).
$$

Часто статистикой называют конкретное значение $T(x_1, x_2, ..., x_n)$, полученное на данной реализации $x_1, x_2, ..., x_n$ выборки.

\textbf{Примеры:}
\begin{itemize}
    \item $\bar{X} = (X_1 + X_2 + ... + X_n)/n$ - выборочное среднее.
    \item $X_{(n)} = \max(X_1, X_2, ..., X_n)$ - максимальное значение в выборке.
    \item медиана, перцентили.
\end{itemize}


\section{Bootstrap}

Пусть имеется реализация некоторой выборки $x_1, x_2, ..., x_n$. Если по каким-либо причинам мы не можем больше сэмплировать из генеральной совокупности, то любая статистика выборки также представляет собой константу: $T(x_1, x_2, ..., x_n) = const$. 

Бутстрепом называется процесс сэмплирования из имеющейся выборки $x_1, x_2, ..., x_n$ подвыборки длины $n$ с возвращением. Проведя эту операцию $k$ раз, можем, в частности, посчитать $k$ значений интересующей нас статистики, то есть фактически исследовать ее возможные эмпирические значения.

Бутстреп позволяет получать эмпирические распределения интересующих нас величин, получать точечные и интервальные оценки, выравнивать количества несбалансированных выборок при A/B тестировании и многое другое.

При однократном выполнении данной процедуры мы используем в среднем только $1 - 1/e \approx 63\%$ всей выборки, что обычно используется в out-of-bag оценках различных алгоритмах, основанных на бутстрепе.


\section{Классический и байесовский подход}

Основные отличия между классическим (частотным) и байесовским подходом отражены в следующей таблице:

\begin{tabular}{ p{3cm}|p{6cm}|p{5cm} }
          & Частотный подход & Байесовский подход \\ \hline 
Идеология & Объективная случайность существует & Любая случайность субъективна \\
Объект    & Неслучайные параметры случайных величин & Распределения случайных величин \\
Метод     & Метод максимального правдоподобия & Теорема Байеса \\
Результат & Точечные и интервальные оценки неизвестных параметров & Распределение неизвестных параметров \\
Применимость & Размер выборки велик по сравнению с кол-вом неизвестных параметров & Размер выборки любой \\ \hline
\end{tabular}

Иными словами, в байесовском подходе любая неизвестная величина считается случайной с некоторым распределением, которое затем может уточняться вогласно новым данным по теореме Байеса. 

\section{Классическая оценка параметров: MLE}

Пусть имеется выборка значений $D = \{x_1, x_2, ..., x_n\}$ некоторой величины $X$, точное распределение которой нам неизвестно. Предполагаем, что плотность распределения $X$ известна с точностью до параметра $\alpha$ (возможно, многомерного): 
$$
X \sim g(x, \alpha).
$$
Величина
$$
L(\alpha|D) = g(D | \alpha) = \prod_{i=1}^n g(x_i | \alpha)
$$
называется \textbf{\textit{правдоподобием}} и представляет собой плотность/вероятность получить именно такие данные $D$ из распределения исходной величины $X$. Естесственно пытаться определить неизвестный параметр $\alpha$ как тот, при котором эта вероятность максимальна. Правдоподобие обычно логарифмируют, что не влияет на оптимальное значение параметра:
$$
\alpha_{MLE} = \argmax{\ln{L(\alpha|D)}}.
$$


\section{Байесовская оценка параметров: MAP}

Пусть имеется выборка значений $D = \{x_1, x_2, ..., x_n\}$ некоторой величины $X$, точное распределение которой нам неизвестно. Предполагаем, что плотность распределения $X$ известна с точностью до параметра $\alpha$ (возможно, многомерного): 
$$
X \sim g(x, \alpha).
$$
Согласно \textbf{\textit{байесовской парадигме}}, неизвестный параметр $\alpha$ трактуется не как число, а как случайная величина, имеющая некоторое распределение: $\alpha \sim f(\alpha)$. Это исходное распределение параметра может быть уточнено с учетом пришедших данных $D$ по формуле Байеса:
$$
f(\alpha | D) = \frac{g(D | \alpha)f(\alpha)}{h(D)}.
$$
Здесь $f$ - априорное распределение $\alpha$, $g(D | *)$ - правдоподобие пришедших данных $D$, 
$h$ - evidence - плотность/вероятность получения именно таких данных.

Процедуру уточнения распределения неизвестных параметров можно повторять по мере получения новых данных, используя полученное на предыдущем шаге апостериорное распределение как априорное для следующего.

MAP оценкой параметра $\alpha$ называется значение
$$
\alpha_{MAP} = \argmax f(\alpha | D).
$$

Важно понимать, что байесовский подход дает оценку не плотности распределения исходных данных $g$ напрямую, а оценку плотности распределения некоторого параметра распределения $g$.

Известными минусами байесовского подхода является необходимость откуда-то брать априорное распределение параметра $f(\alpha)$ и вычисление знаменателя $h(D)$, что является обычно вычислительно сложной задачей. Тем не менее, обычно выбор априорного распределения не оказывает сильного влияния на результат, а знаменатель $h(D)$, будучи не зависимой от $\alpha$, не влияет на $\alpha_{MAP}$.


\section{Сравнение классической и байесовской оценок параметров}

Пусть имеется выборка значений $D = \{x_1, x_2, ..., x_n\}$ некоторой величины $X$, точное распределение которой нам неизвестно. Предполагаем, что плотность распределения $X$ известна с точностью до параметра $\alpha$ (возможно, многомерного): 
$$
X \sim g(x, \alpha).
$$

Согласно \textbf{\textit{классическому подходу}}, величина $\alpha$ трактуется как фиксированное (хоть и неизвестное) число, которое находится исходя из желания максимизировать вероятность того, что исходные данные $D$ пришли именно из этого распределения.

Согласно \textbf{\textit{байесовскому подходу}}, величина $\alpha$ трактуется как случайная с некоторым известным априорным распределением. Основной целью в этом случае выступает нахождение апостериорного распределения величины $\alpha$, уточненного согласно пришедшим данным $D$ по формуле Байеса.

Если интервал изменения неизвестного параметра $\alpha$ конечен, а о самом $\alpha$ мы не имеем никаких априорных знаний, естественно положить априорное распределение $\alpha$ равномерным. В этом случае результаты баейсовской и классической оценок совпадают: $\alpha_{MLE} = \alpha_{MAP}$.


\section{Классический доверительный интервал}


\section{Байесовский доверительный интервал}


\section{Основные дискретные распределения}

$https://medium.com/@srowen/common-probability-distributions-347e6b945ce4$


\section{Основные непрерывные распределения}


\section{Метод Монте-Карло}


\section{Байесовская оптимизация}


\section{Матричные разложения}

...может разделить главу на части...


\section{К-Л дивергенция}

Дивергенция Кульбака-Лейблера (относительная энтропия) - мера сходства двух распределений. Для RV $P$, $Q$ вычисляется как
$$
K(p, q) = -\sum_{i=0}^np_i\log_2\frac{q_i}{p_i}.
$$

Определено для распределений $q_i = 0 \Rightarrow p_i=0$.
В байесовской интерпретации это информация, приобретенная при переходе от априорного распределения $p$ к апостериорному распределению $q$.

К-Л дивергенция всегда неотрицательна и аддитивна в следующем смысле: если $P_1$, $P_2$ - независимые RV, $Q_1$, $Q_2$ - тоже, то для совместных плотностей распределения $P$ и $Q$ справедливо:
$$
K(P, Q) =  K(P_1, Q_1) + K(P_2, Q_2).
$$

К-Л дивергенция может использоваться как метрика между распределениями, так как при $n \rightarrow \infty$ справедливо
$$
K(P_n, Q) \rightarrow 0 \quad \Rightarrow \quad P_n \rightarrow Q
$$
в смысле распределений.

\section{Энтропия}


\section{Кросс-энтропия}


\section{Квантили}


\section{Точечные оценки}


\section{Интервальные оценки}


\section{Проверка гипотез ***}

Пусть $x_1, x_2, ..., x_n$ - выборка из генеральной совокупности $X$, распределение которой заранее неизвестно.
Требуется проверить некоторое утверждение о распределении генеральной совокупности $X$ исходя из имеющейся выборки.

Общий подход к решению таких задач состоит в следующем:
\begin{enumerate}
    \item Формулируется основная гипотеза $H_0$ о распределении $X$ и некоторая альтернативная гипотеза $H_1$, которая может являться полным отрицанием $H_0$ (двусторонняя альтернатива), но не обязательно (односторонние и др. альтернативы).
    \item Выбирается некоторая статистика $T$ исходя из условия, что нулевая гипотеза $H_0$ верна тогда и только тогда, когда распределение $T$ известно: $T \sim F(t|H_0)$ (нулевое распределение статистики). 
    \item Вычисляется значение $t^*$ статистики $T$ на имеющейся выборке. По известному распределению $F$ можно судить, насколько вероятно получить значения~$t^*$.
    \item Выбирается уровень значимости $\alpha$.
    \item Вычисляется достигаемый уровень значимости $p_{value}$ и сравнивается с $\alpha$. Если $p_{value} > \alpha$, то нулевая гипотеза $H_0$ не может быть отвергнута, а если $p_{value} \leqslant \alpha$, гипотеза $H_0$ отвергается в пользу альтернативной $H_1$.
\end{enumerate}

\textbf{Пример:} TODO

Обычно нулевая гипотеза $H_0$ означает, что "ничего интересного не происходит", а альтернативная, напротив, говорит о том, что "что-то произошло".

\section{Достигаемый уровень значимости, $p_{value}$ ***}

Пусть статистика $T$ приняла на выборке $x_1, x_2, ..., x_n$ значение $t^*$. Так как нулевое распределение статистики известно, по значению $t^*$ можно судить, насколько оно характерно для данного распределения. Именно, для случая правосторонней альтернативной определим значение

$$
p_{value} = \mathbb{P}(T \geqslant t^* | H_0).
$$

TODO картинка

Если бы $H_0$ была справедлива, то значение $t^*$ вероятно оказалось бы около матожидания распределения $T$ и, как следствие, $p_{value}$ было бы велико. В противном случае, если $t^*$ оказалось далеко правее среднего, $p_{value}$ мало, и нулевую гипотезу следует отвергнуть в пользу правосторонней альтернативы $H_1$.

Число $p_{value}$ называется достигаемым уровнем значимости. Оно сравнивается с заранее заданным уровнем значимости $\alpha$, и если $p_{value} > \alpha$, то нулевая гипотеза $H_0$ не может быть отвергнута, а если $p_{value} \leqslant \alpha$, гипотеза $H_0$ отвергается в пользу альтернативной $H_1$.

Аналогичные рассуждения справедливы для случаев лево- и двусторонней альтернативы.

\section{Множественная проверка гипотез}

Пусть имеется ряд статистических гипотез, которые следует проверить в совокупности, то есть совокупная нулевая гипотеза состоит в том, что во все исходные нулевые гипотезы верны. Пусть $\alpha$ - уровень значимости для всех исходных гипотез. Опрерировать тем же уровнем значимости для совокупной гипотезы было бы неверно, так как отвергание совокупной нулевой гипотезы означало бы, что хоть одна из исходных гипотез отвергается. Вероятность этого события
$$
1 - (1 - \alpha)^m,
$$
экспоненциально близка к 1 при больших $m$. Таким образом, вероятность совершить ошибку первого рода для множественной проверки гипотез всегда очень близка к 1, если использовать тот же уровень значимости, что и для исходных гипотез.

\textbf{Пример:} Некоторое лекарство исследуется на $m$ возможных побочных эффектов. Чем больше $m$, тем выше вероятность, что хоть один побочный эффект проявится. Это не означает, что этот побочный эффект характерен для лекарства, он мог проявиться просто случайно.

\section{Коррекции на множественную проверку гипотез}

\section{Ошибки I и II рода}


\section{Уровень значимости, $\alpha$}

Уровень значимости $\alpha$ - вероятность ошибки первого рода, то есть вероятность отвергнуть верную нулевую гипотезу.


\section{Мощность статистического критерия}

Пусть $\beta$ - вероятности ошибки второго рода, то есть вероятности принять неверную нулевую гипотезу. Величина $1 - \beta$ называется мощностью статистического критерия. Таким образом, мощность статистического критерия - это вероятность отвергнуть неверную нулевую гипотезу.

\section{Основные задачи статистики}

...из лекций новосиба  курсера...


\section{Параметрические и непараметрические критерии, бутстреп}


\section{Проверка основных гипотез}


\section{Корреляция Пирсона}


\section{Корреляция Спирмена}


\section{Корреляция Метьюса}


\section{Корреляция Крамера}


\section{Z-тест Фишера}


\section{T-тест Стьюдента}


\section{Критерий Пирсона $\chi^2$}


\section{Точный тест Фишера}


\section{Проклятье размерности}



